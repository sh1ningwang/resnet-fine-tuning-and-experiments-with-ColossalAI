{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grVXCT4XK2Ik"
      },
      "source": [
        "# Mount source code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHKtD42lCwck",
        "outputId": "43e5ce4f-4f7b-4329-abfe-6ba9d94ecf6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3k_etZ-2I0ZX"
      },
      "source": [
        "# Check GPU specs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njcKkgHVI2jX",
        "outputId": "1f6da5c8-8ebe-4af0-fd48-3d06d0c30228"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Apr 10 20:49:01 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0              46W / 400W |      2MiB / 40960MiB |      0%      Default |\n",
            "|                                         |                      |             Disabled |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHP4rTNf_5-o"
      },
      "source": [
        "# path and scripts definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hc-12CEK_89P"
      },
      "outputs": [],
      "source": [
        "resnet_experiment_root_path = \"/content/drive/MyDrive/CS5260_A6\" # Change this according to the Google Drive folder name\n",
        "resnet_experiment_requirements_path = f\"{resnet_experiment_root_path}/requirements.txt\"\n",
        "resnet_experiment_model_path = f\"{resnet_experiment_root_path}/model\"\n",
        "resnet_experiment_train_script_path = f\"{resnet_experiment_root_path}/train.py\"\n",
        "resnet_experiment_eval_script_path = f\"{resnet_experiment_root_path}/eval.py\"\n",
        "colossal_ai_run = \"/usr/local/bin/colossalai run\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZL16cRELA46"
      },
      "source": [
        "# Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0lon9wvLF-j",
        "outputId": "94a19f13-7880-40ba-87c8-198627722b29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting colossalai (from -r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1))\n",
            "  Downloading colossalai-0.3.6.tar.gz (1.1 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m0.8/1.1 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 2)) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 3)) (0.17.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 4)) (4.66.2)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 5)) (7.4.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1)) (1.25.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1)) (24.0)\n",
            "Collecting pre-commit (from colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1))\n",
            "  Downloading pre_commit-3.7.0-py2.py3-none-any.whl (204 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.2/204.2 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1)) (13.7.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1)) (8.1.7)\n",
            "Collecting fabric (from colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1))\n",
            "  Downloading fabric-3.2.2-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting contexttimer (from colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1))\n",
            "  Downloading contexttimer-0.3.3.tar.gz (4.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ninja (from colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1))\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1)) (0.4.2)\n",
            "Collecting einops (from colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1))\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1)) (2.6.4)\n",
            "Collecting ray (from colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1))\n",
            "  Downloading ray-2.10.0-cp310-cp310-manylinux2014_x86_64.whl (65.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.1/65.1 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1)) (0.1.99)\n",
            "Requirement already satisfied: google in /usr/local/lib/python3.10/dist-packages (from colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1)) (2.0.3)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1)) (3.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 2)) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 2)) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 2)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 2)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 2)) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 2)) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 2))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 2))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 2))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 2))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 2))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 2))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 2))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 2))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 2))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 2))\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 2))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 2)) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 2))\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 3)) (9.4.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 5)) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 5)) (1.4.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 5)) (1.2.0)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 5)) (2.0.1)\n",
            "Collecting invoke>=2.0 (from fabric->colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1))\n",
            "  Downloading invoke-2.2.0-py3-none-any.whl (160 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.3/160.3 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting paramiko>=2.4 (from fabric->colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1))\n",
            "  Downloading paramiko-3.4.0-py3-none-any.whl (225 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.9/225.9 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting decorator>=5 (from fabric->colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1))\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting deprecated>=1.2 (from fabric->colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1))\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from google->colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1)) (4.12.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 2)) (2.1.5)\n",
            "Collecting cfgv>=2.0.0 (from pre-commit->colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1))\n",
            "  Downloading cfgv-3.4.0-py2.py3-none-any.whl (7.2 kB)\n",
            "Collecting identify>=1.0.0 (from pre-commit->colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1))\n",
            "  Downloading identify-2.5.35-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.9/98.9 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nodeenv>=0.11.1 (from pre-commit->colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1))\n",
            "  Downloading nodeenv-1.8.0-py2.py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from pre-commit->colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1)) (6.0.1)\n",
            "Collecting virtualenv>=20.10.0 (from pre-commit->colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1))\n",
            "  Downloading virtualenv-20.25.1-py3-none-any.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1)) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic->colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1)) (2.16.3)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray->colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1)) (4.19.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray->colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1)) (1.0.8)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray->colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray->colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray->colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1)) (2.31.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1)) (2.16.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2->fabric->colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1)) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1)) (0.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nodeenv>=0.11.1->pre-commit->colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1)) (67.7.2)\n",
            "Collecting bcrypt>=3.2 (from paramiko>=2.4->fabric->colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1))\n",
            "  Downloading bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl (698 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography>=3.3 in /usr/local/lib/python3.10/dist-packages (from paramiko>=2.4->fabric->colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1)) (42.0.5)\n",
            "Collecting pynacl>=1.5 (from paramiko>=2.4->fabric->colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1))\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit->colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1))\n",
            "  Downloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.10.0->pre-commit->colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1)) (4.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->google->colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1)) (2.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray->colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1)) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray->colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1)) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray->colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1)) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray->colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1)) (0.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray->colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray->colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray->colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray->colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1)) (2024.2.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.3->paramiko>=2.4->fabric->colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1)) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.3->paramiko>=2.4->fabric->colossalai->-r /content/drive/MyDrive/CS5260_A6/requirements.txt (line 1)) (2.22)\n",
            "Building wheels for collected packages: colossalai, contexttimer\n",
            "  Building wheel for colossalai (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for colossalai: filename=colossalai-0.3.6-py3-none-any.whl size=1389734 sha256=1f26c0b6ee2aa5ae4a64280edf57ce834aad9ccc308071cd6d1e548ab7836e17\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/52/8e/8ff9fb0a6ec328844d9344eb1e1adc29f3d05886adb2a3551a\n",
            "  Building wheel for contexttimer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for contexttimer: filename=contexttimer-0.3.3-py3-none-any.whl size=5804 sha256=82cd704a6870cf91fdaa8ac53e116c2290dbf6f753483339645070f73806b653\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/1c/da/cfd97201d88ccce214427fa84a5caeb91fef7c5a1b4c4312b4\n",
            "Successfully built colossalai contexttimer\n",
            "Installing collected packages: ninja, distlib, contexttimer, virtualenv, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nodeenv, invoke, identify, einops, deprecated, decorator, cfgv, bcrypt, pynacl, pre-commit, nvidia-cusparse-cu12, nvidia-cudnn-cu12, paramiko, nvidia-cusolver-cu12, ray, fabric, colossalai\n",
            "  Attempting uninstall: decorator\n",
            "    Found existing installation: decorator 4.4.2\n",
            "    Uninstalling decorator-4.4.2:\n",
            "      Successfully uninstalled decorator-4.4.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "moviepy 1.0.3 requires decorator<5.0,>=4.0.2, but you have decorator 5.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bcrypt-4.1.2 cfgv-3.4.0 colossalai-0.3.6 contexttimer-0.3.3 decorator-5.1.1 deprecated-1.2.14 distlib-0.3.8 einops-0.7.0 fabric-3.2.2 identify-2.5.35 invoke-2.2.0 ninja-1.11.1.1 nodeenv-1.8.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 paramiko-3.4.0 pre-commit-3.7.0 pynacl-1.5.0 ray-2.10.0 virtualenv-20.25.1\n"
          ]
        }
      ],
      "source": [
        "pip_install_command = f\"pip install -r {resnet_experiment_requirements_path}\"\n",
        "!{pip_install_command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9wFbg9MAvnK"
      },
      "source": [
        "# Make sure colossalai is installed successfully"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQO4voB2A0_G",
        "outputId": "ed5a5bc9-6937-4087-be3b-040681ed1ed0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#### Installation Report ####\n",
            "\n",
            "------------ Environment ------------\n",
            "Colossal-AI version: 0.3.6\n",
            "PyTorch version: 2.2.1\n",
            "System CUDA version: 12.2\n",
            "CUDA version required by PyTorch: 12.1\n",
            "\n",
            "Note:\n",
            "1. The table above checks the versions of the libraries/tools in the current environment\n",
            "2. If the System CUDA version is N/A, you can set the CUDA_HOME environment variable to locate it\n",
            "3. If the CUDA version required by PyTorch is N/A, you probably did not install a CUDA-compatible PyTorch. This value is give by torch.version.cuda and you can go to https://pytorch.org/get-started/locally/ to download the correct version.\n",
            "\n",
            "------------ CUDA Extensions AOT Compilation ------------\n",
            "Found AOT CUDA Extension: ✓\n",
            "PyTorch version used for AOT compilation: N/A\n",
            "CUDA version used for AOT compilation: N/A\n",
            "\n",
            "Note:\n",
            "1. AOT (ahead-of-time) compilation of the CUDA kernels occurs during installation when the environment variable BUILD_EXT=1 is set\n",
            "2. If AOT compilation is not enabled, stay calm as the CUDA kernels can still be built during runtime\n",
            "\n",
            "------------ Compatibility ------------\n",
            "PyTorch version match: N/A\n",
            "System and PyTorch CUDA version match: x\n",
            "System and Colossal-AI CUDA version match: N/A\n",
            "\n",
            "Note:\n",
            "1. The table above checks the version compatibility of the libraries/tools in the current environment\n",
            "   - PyTorch version mismatch: whether the PyTorch version in the current environment is compatible with the PyTorch version used for AOT compilation\n",
            "   - System and PyTorch CUDA version match: whether the CUDA version in the current environment is compatible with the CUDA version required by PyTorch\n",
            "   - System and Colossal-AI CUDA version match: whether the CUDA version in the current environment is compatible with the CUDA version used for AOT compilation\n"
          ]
        }
      ],
      "source": [
        "!/usr/local/bin/colossalai check -i"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qv8W9O7ZO4Jm"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "unAjw5jNO6lU",
        "outputId": "97a7f715-3dd2-4c07-faa5-d3762ee84bb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/colossalai/pipeline/schedule/_utils.py:19: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _register_pytree_node(OrderedDict, _odict_flatten, _odict_unflatten)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/_pytree.py:254: UserWarning: <class 'collections.OrderedDict'> is already registered as pytree node. Overwriting the previous registration.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/shardformer/layer/normalization.py:45: UserWarning: Please install apex from source (https://github.com/NVIDIA/apex) to use the fused layernorm kernel\n",
            "  warnings.warn(\"Please install apex from source (https://github.com/NVIDIA/apex) to use the fused layernorm kernel\")\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/initialize.py:48: UserWarning: `config` is deprecated and will be removed soon.\n",
            "  warnings.warn(\"`config` is deprecated and will be removed soon.\")\n",
            "[04/10/24 20:50:42] INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /usr/local/lib/python3.10/dist-packages/colossalai/initialize.py:67    \n",
            "                             launch                                                                 \n",
            "                    INFO     colossalai - colossalai - INFO: Distributed environment is initialized,\n",
            "                             world size: 1                                                          \n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n",
            "100%|██████████| 170498071/170498071 [00:12<00:00, 13200020.40it/s]\n",
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/kernel/extensions/utils.py:96: UserWarning: [extension] The CUDA version on the system (12.2) does not match with the version (12.1) torch was compiled with. The mismatch is found in the minor version. As the APIs are compatible, we will allow compilation to proceed. If you encounter any issue when using the built kernel, please try to build it again with fully matched CUDA versions\n",
            "  warnings.warn(\n",
            "[extension] Compiling the JIT cpu_adam_x86 kernel during runtime now\n",
            "[extension] Time taken to compile cpu_adam_x86 op: 36.72586536407471 seconds\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/kernel/extensions/utils.py:96: UserWarning: [extension] The CUDA version on the system (12.2) does not match with the version (12.1) torch was compiled with. The mismatch is found in the minor version. As the APIs are compatible, we will allow compilation to proceed. If you encounter any issue when using the built kernel, please try to build it again with fully matched CUDA versions\n",
            "  warnings.warn(\n",
            "[extension] Compiling the JIT fused_optim_cuda kernel during runtime now\n",
            "[extension] Time taken to compile fused_optim_cuda op: 64.9852876663208 seconds\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/nn/optimizer/hybrid_adam.py:90: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)\n",
            "  self._dummy_overflow_buf = torch.cuda.IntTensor([0])\n",
            "Epoch [1/80]:   0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/colossalai/nn/optimizer/nvme_optimizer.py:55: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  numel += p.storage().size()\n",
            "Epoch [1/80]: 100%|██████████| 390/390 [00:20<00:00, 19.13it/s, loss=1.27]\n",
            "Epoch [2/80]: 100%|██████████| 390/390 [00:19<00:00, 19.68it/s, loss=1.01]\n",
            "Epoch [3/80]: 100%|██████████| 390/390 [00:19<00:00, 19.51it/s, loss=0.918]\n",
            "Epoch [4/80]: 100%|██████████| 390/390 [00:19<00:00, 19.70it/s, loss=0.813]\n",
            "Epoch [5/80]: 100%|██████████| 390/390 [00:19<00:00, 19.68it/s, loss=0.861]\n",
            "Epoch [6/80]: 100%|██████████| 390/390 [00:19<00:00, 19.69it/s, loss=0.733]\n",
            "Epoch [7/80]: 100%|██████████| 390/390 [00:19<00:00, 19.87it/s, loss=0.668]\n",
            "Epoch [8/80]: 100%|██████████| 390/390 [00:19<00:00, 19.79it/s, loss=0.506]\n",
            "Epoch [9/80]: 100%|██████████| 390/390 [00:19<00:00, 19.76it/s, loss=0.511]\n",
            "Epoch [10/80]: 100%|██████████| 390/390 [00:19<00:00, 19.71it/s, loss=0.501]\n",
            "Epoch [11/80]: 100%|██████████| 390/390 [00:19<00:00, 19.79it/s, loss=0.467]\n",
            "Epoch [12/80]: 100%|██████████| 390/390 [00:19<00:00, 19.91it/s, loss=0.548]\n",
            "Epoch [13/80]: 100%|██████████| 390/390 [00:19<00:00, 19.89it/s, loss=0.445]\n",
            "Epoch [14/80]: 100%|██████████| 390/390 [00:19<00:00, 19.72it/s, loss=0.518]\n",
            "Epoch [15/80]: 100%|██████████| 390/390 [00:19<00:00, 19.87it/s, loss=0.405]\n",
            "Epoch [16/80]: 100%|██████████| 390/390 [00:20<00:00, 19.37it/s, loss=0.403]\n",
            "Epoch [17/80]: 100%|██████████| 390/390 [00:19<00:00, 19.71it/s, loss=0.43]\n",
            "Epoch [18/80]: 100%|██████████| 390/390 [00:19<00:00, 19.67it/s, loss=0.388]\n",
            "Epoch [19/80]: 100%|██████████| 390/390 [00:19<00:00, 19.60it/s, loss=0.448]\n",
            "Epoch [20/80]: 100%|██████████| 390/390 [00:19<00:00, 19.77it/s, loss=0.374]\n",
            "Epoch [21/80]: 100%|██████████| 390/390 [00:19<00:00, 19.58it/s, loss=0.258]\n",
            "Epoch [22/80]: 100%|██████████| 390/390 [00:19<00:00, 19.87it/s, loss=0.308]\n",
            "Epoch [23/80]: 100%|██████████| 390/390 [00:19<00:00, 19.85it/s, loss=0.228]\n",
            "Epoch [24/80]: 100%|██████████| 390/390 [00:19<00:00, 19.53it/s, loss=0.201]\n",
            "Epoch [25/80]: 100%|██████████| 390/390 [00:19<00:00, 19.71it/s, loss=0.214]\n",
            "Epoch [26/80]: 100%|██████████| 390/390 [00:19<00:00, 19.55it/s, loss=0.214]\n",
            "Epoch [27/80]: 100%|██████████| 390/390 [00:20<00:00, 19.47it/s, loss=0.221]\n",
            "Epoch [28/80]: 100%|██████████| 390/390 [00:19<00:00, 19.65it/s, loss=0.23]\n",
            "Epoch [29/80]: 100%|██████████| 390/390 [00:19<00:00, 19.75it/s, loss=0.263]\n",
            "Epoch [30/80]: 100%|██████████| 390/390 [00:19<00:00, 19.79it/s, loss=0.232]\n",
            "Epoch [31/80]: 100%|██████████| 390/390 [00:20<00:00, 19.36it/s, loss=0.249]\n",
            "Epoch [32/80]: 100%|██████████| 390/390 [00:20<00:00, 19.45it/s, loss=0.195]\n",
            "Epoch [33/80]: 100%|██████████| 390/390 [00:20<00:00, 19.44it/s, loss=0.237]\n",
            "Epoch [34/80]: 100%|██████████| 390/390 [00:19<00:00, 19.60it/s, loss=0.188]\n",
            "Epoch [35/80]: 100%|██████████| 390/390 [00:19<00:00, 19.83it/s, loss=0.21]\n",
            "Epoch [36/80]: 100%|██████████| 390/390 [00:19<00:00, 19.77it/s, loss=0.147]\n",
            "Epoch [37/80]: 100%|██████████| 390/390 [00:19<00:00, 19.72it/s, loss=0.205]\n",
            "Epoch [38/80]: 100%|██████████| 390/390 [00:19<00:00, 19.79it/s, loss=0.221]\n",
            "Epoch [39/80]: 100%|██████████| 390/390 [00:19<00:00, 19.64it/s, loss=0.209]\n",
            "Epoch [40/80]: 100%|██████████| 390/390 [00:19<00:00, 19.78it/s, loss=0.0889]\n",
            "Epoch [41/80]: 100%|██████████| 390/390 [00:19<00:00, 19.78it/s, loss=0.141]\n",
            "Epoch [42/80]: 100%|██████████| 390/390 [00:19<00:00, 19.79it/s, loss=0.139]\n",
            "Epoch [43/80]: 100%|██████████| 390/390 [00:19<00:00, 19.65it/s, loss=0.148]\n",
            "Epoch [44/80]: 100%|██████████| 390/390 [00:19<00:00, 19.76it/s, loss=0.131]\n",
            "Epoch [45/80]: 100%|██████████| 390/390 [00:19<00:00, 19.78it/s, loss=0.143]\n",
            "Epoch [46/80]: 100%|██████████| 390/390 [00:19<00:00, 19.79it/s, loss=0.109]\n",
            "Epoch [47/80]: 100%|██████████| 390/390 [00:20<00:00, 19.05it/s, loss=0.15]\n",
            "Epoch [48/80]: 100%|██████████| 390/390 [00:20<00:00, 18.64it/s, loss=0.123]\n",
            "Epoch [49/80]: 100%|██████████| 390/390 [00:20<00:00, 18.67it/s, loss=0.0904]\n",
            "Epoch [50/80]: 100%|██████████| 390/390 [00:20<00:00, 18.70it/s, loss=0.0773]\n",
            "Epoch [51/80]: 100%|██████████| 390/390 [00:20<00:00, 18.64it/s, loss=0.0616]\n",
            "Epoch [52/80]: 100%|██████████| 390/390 [00:20<00:00, 18.81it/s, loss=0.0956]\n",
            "Epoch [53/80]: 100%|██████████| 390/390 [00:20<00:00, 18.63it/s, loss=0.114]\n",
            "Epoch [54/80]: 100%|██████████| 390/390 [00:20<00:00, 18.91it/s, loss=0.0534]\n",
            "Epoch [55/80]: 100%|██████████| 390/390 [00:20<00:00, 18.75it/s, loss=0.145]\n",
            "Epoch [56/80]: 100%|██████████| 390/390 [00:20<00:00, 18.95it/s, loss=0.101]\n",
            "Epoch [57/80]: 100%|██████████| 390/390 [00:20<00:00, 18.79it/s, loss=0.0654]\n",
            "Epoch [58/80]: 100%|██████████| 390/390 [00:20<00:00, 18.85it/s, loss=0.062]\n",
            "Epoch [59/80]: 100%|██████████| 390/390 [00:20<00:00, 18.69it/s, loss=0.0578]\n",
            "Epoch [60/80]: 100%|██████████| 390/390 [00:19<00:00, 19.54it/s, loss=0.0477]\n",
            "Epoch [61/80]: 100%|██████████| 390/390 [00:20<00:00, 19.02it/s, loss=0.0673]\n",
            "Epoch [62/80]: 100%|██████████| 390/390 [00:20<00:00, 19.02it/s, loss=0.0461]\n",
            "Epoch [63/80]: 100%|██████████| 390/390 [00:20<00:00, 19.31it/s, loss=0.127]\n",
            "Epoch [64/80]: 100%|██████████| 390/390 [00:20<00:00, 19.30it/s, loss=0.0715]\n",
            "Epoch [65/80]: 100%|██████████| 390/390 [00:20<00:00, 19.19it/s, loss=0.0767]\n",
            "Epoch [66/80]: 100%|██████████| 390/390 [00:20<00:00, 19.04it/s, loss=0.049]\n",
            "Epoch [67/80]: 100%|██████████| 390/390 [00:20<00:00, 19.28it/s, loss=0.0758]\n",
            "Epoch [68/80]: 100%|██████████| 390/390 [00:20<00:00, 19.25it/s, loss=0.0589]\n",
            "Epoch [69/80]: 100%|██████████| 390/390 [00:20<00:00, 19.28it/s, loss=0.0442]\n",
            "Epoch [70/80]: 100%|██████████| 390/390 [00:20<00:00, 19.13it/s, loss=0.0253]\n",
            "Epoch [71/80]: 100%|██████████| 390/390 [00:20<00:00, 19.26it/s, loss=0.0575]\n",
            "Epoch [72/80]: 100%|██████████| 390/390 [00:20<00:00, 19.16it/s, loss=0.0986]\n",
            "Epoch [73/80]: 100%|██████████| 390/390 [00:20<00:00, 19.05it/s, loss=0.0907]\n",
            "Epoch [74/80]: 100%|██████████| 390/390 [00:20<00:00, 19.19it/s, loss=0.0436]\n",
            "Epoch [75/80]: 100%|██████████| 390/390 [00:20<00:00, 19.25it/s, loss=0.0344]\n",
            "Epoch [76/80]: 100%|██████████| 390/390 [00:20<00:00, 19.04it/s, loss=0.0788]\n",
            "Epoch [77/80]: 100%|██████████| 390/390 [00:20<00:00, 19.21it/s, loss=0.0788]\n",
            "Epoch [78/80]: 100%|██████████| 390/390 [00:20<00:00, 19.36it/s, loss=0.128]\n",
            "Epoch [79/80]: 100%|██████████| 390/390 [00:20<00:00, 19.49it/s, loss=0.0966]\n",
            "Epoch [80/80]: 100%|██████████| 390/390 [00:19<00:00, 19.51it/s, loss=0.118]\n",
            "Accuracy of the model on the test images: 84.54 %\n",
            "\n",
            "====== Training on All Nodes =====\n",
            "127.0.0.1: success\n",
            "\n",
            "====== Stopping All Nodes =====\n",
            "127.0.0.1: finish\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/pipeline/schedule/_utils.py:19: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _register_pytree_node(OrderedDict, _odict_flatten, _odict_unflatten)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/_pytree.py:254: UserWarning: <class 'collections.OrderedDict'> is already registered as pytree node. Overwriting the previous registration.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/shardformer/layer/normalization.py:45: UserWarning: Please install apex from source (https://github.com/NVIDIA/apex) to use the fused layernorm kernel\n",
            "  warnings.warn(\"Please install apex from source (https://github.com/NVIDIA/apex) to use the fused layernorm kernel\")\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/initialize.py:48: UserWarning: `config` is deprecated and will be removed soon.\n",
            "  warnings.warn(\"`config` is deprecated and will be removed soon.\")\n",
            "[04/10/24 21:23:27] INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /usr/local/lib/python3.10/dist-packages/colossalai/initialize.py:67    \n",
            "                             launch                                                                 \n",
            "                    INFO     colossalai - colossalai - INFO: Distributed environment is initialized,\n",
            "                             world size: 1                                                          \n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/kernel/extensions/utils.py:96: UserWarning: [extension] The CUDA version on the system (12.2) does not match with the version (12.1) torch was compiled with. The mismatch is found in the minor version. As the APIs are compatible, we will allow compilation to proceed. If you encounter any issue when using the built kernel, please try to build it again with fully matched CUDA versions\n",
            "  warnings.warn(\n",
            "[extension] Compiling the JIT cpu_adam_x86 kernel during runtime now\n",
            "[extension] Time taken to compile cpu_adam_x86 op: 0.10821366310119629 seconds\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/kernel/extensions/utils.py:96: UserWarning: [extension] The CUDA version on the system (12.2) does not match with the version (12.1) torch was compiled with. The mismatch is found in the minor version. As the APIs are compatible, we will allow compilation to proceed. If you encounter any issue when using the built kernel, please try to build it again with fully matched CUDA versions\n",
            "  warnings.warn(\n",
            "[extension] Compiling the JIT fused_optim_cuda kernel during runtime now\n",
            "[extension] Time taken to compile fused_optim_cuda op: 0.12401866912841797 seconds\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/nn/optimizer/hybrid_adam.py:90: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)\n",
            "  self._dummy_overflow_buf = torch.cuda.IntTensor([0])\n",
            "Epoch [1/80]:   0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/colossalai/nn/optimizer/nvme_optimizer.py:55: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  numel += p.storage().size()\n",
            "Epoch [1/80]: 100%|██████████| 390/390 [00:21<00:00, 17.76it/s, loss=1.33]\n",
            "Epoch [2/80]: 100%|██████████| 390/390 [00:21<00:00, 18.38it/s, loss=1.1]\n",
            "Epoch [3/80]: 100%|██████████| 390/390 [00:21<00:00, 18.38it/s, loss=0.988]\n",
            "Epoch [4/80]: 100%|██████████| 390/390 [00:21<00:00, 18.48it/s, loss=0.792]\n",
            "Epoch [5/80]: 100%|██████████| 390/390 [00:21<00:00, 18.22it/s, loss=0.744]\n",
            "Epoch [6/80]: 100%|██████████| 390/390 [00:21<00:00, 18.36it/s, loss=0.76]\n",
            "Epoch [7/80]: 100%|██████████| 390/390 [00:21<00:00, 17.79it/s, loss=0.559]\n",
            "Epoch [8/80]: 100%|██████████| 390/390 [00:21<00:00, 17.84it/s, loss=0.607]\n",
            "Epoch [9/80]: 100%|██████████| 390/390 [00:21<00:00, 17.92it/s, loss=0.561]\n",
            "Epoch [10/80]: 100%|██████████| 390/390 [00:21<00:00, 17.96it/s, loss=0.529]\n",
            "Epoch [11/80]: 100%|██████████| 390/390 [00:22<00:00, 17.65it/s, loss=0.45]\n",
            "Epoch [12/80]: 100%|██████████| 390/390 [00:22<00:00, 17.72it/s, loss=0.598]\n",
            "Epoch [13/80]: 100%|██████████| 390/390 [00:21<00:00, 17.89it/s, loss=0.412]\n",
            "Epoch [14/80]: 100%|██████████| 390/390 [00:21<00:00, 17.84it/s, loss=0.443]\n",
            "Epoch [15/80]: 100%|██████████| 390/390 [00:21<00:00, 17.94it/s, loss=0.494]\n",
            "Epoch [16/80]: 100%|██████████| 390/390 [00:21<00:00, 17.79it/s, loss=0.421]\n",
            "Epoch [17/80]: 100%|██████████| 390/390 [00:21<00:00, 17.81it/s, loss=0.408]\n",
            "Epoch [18/80]: 100%|██████████| 390/390 [00:21<00:00, 17.78it/s, loss=0.403]\n",
            "Epoch [19/80]: 100%|██████████| 390/390 [00:21<00:00, 17.79it/s, loss=0.423]\n",
            "Epoch [20/80]: 100%|██████████| 390/390 [00:21<00:00, 17.97it/s, loss=0.347]\n",
            "Epoch [21/80]: 100%|██████████| 390/390 [00:21<00:00, 17.78it/s, loss=0.287]\n",
            "Epoch [22/80]: 100%|██████████| 390/390 [00:21<00:00, 17.82it/s, loss=0.233]\n",
            "Epoch [23/80]: 100%|██████████| 390/390 [00:21<00:00, 18.08it/s, loss=0.237]\n",
            "Epoch [24/80]: 100%|██████████| 390/390 [00:21<00:00, 17.85it/s, loss=0.204]\n",
            "Epoch [25/80]: 100%|██████████| 390/390 [00:21<00:00, 17.96it/s, loss=0.252]\n",
            "Epoch [26/80]: 100%|██████████| 390/390 [00:21<00:00, 17.77it/s, loss=0.204]\n",
            "Epoch [27/80]: 100%|██████████| 390/390 [00:21<00:00, 17.89it/s, loss=0.225]\n",
            "Epoch [28/80]: 100%|██████████| 390/390 [00:21<00:00, 18.16it/s, loss=0.242]\n",
            "Epoch [29/80]: 100%|██████████| 390/390 [00:21<00:00, 18.03it/s, loss=0.232]\n",
            "Epoch [30/80]: 100%|██████████| 390/390 [00:21<00:00, 17.98it/s, loss=0.2]\n",
            "Epoch [31/80]: 100%|██████████| 390/390 [00:21<00:00, 17.76it/s, loss=0.24]\n",
            "Epoch [32/80]: 100%|██████████| 390/390 [00:21<00:00, 17.90it/s, loss=0.25]\n",
            "Epoch [33/80]: 100%|██████████| 390/390 [00:21<00:00, 17.96it/s, loss=0.247]\n",
            "Epoch [34/80]: 100%|██████████| 390/390 [00:21<00:00, 17.97it/s, loss=0.275]\n",
            "Epoch [35/80]: 100%|██████████| 390/390 [00:21<00:00, 17.85it/s, loss=0.195]\n",
            "Epoch [36/80]: 100%|██████████| 390/390 [00:21<00:00, 17.93it/s, loss=0.169]\n",
            "Epoch [37/80]: 100%|██████████| 390/390 [00:21<00:00, 18.10it/s, loss=0.194]\n",
            "Epoch [38/80]: 100%|██████████| 390/390 [00:21<00:00, 17.86it/s, loss=0.154]\n",
            "Epoch [39/80]: 100%|██████████| 390/390 [00:21<00:00, 18.10it/s, loss=0.251]\n",
            "Epoch [40/80]: 100%|██████████| 390/390 [00:22<00:00, 17.71it/s, loss=0.104]\n",
            "Epoch [41/80]: 100%|██████████| 390/390 [00:21<00:00, 17.82it/s, loss=0.123]\n",
            "Epoch [42/80]: 100%|██████████| 390/390 [00:21<00:00, 17.95it/s, loss=0.0739]\n",
            "Epoch [43/80]: 100%|██████████| 390/390 [00:21<00:00, 17.83it/s, loss=0.159]\n",
            "Epoch [44/80]: 100%|██████████| 390/390 [00:21<00:00, 17.77it/s, loss=0.107]\n",
            "Epoch [45/80]: 100%|██████████| 390/390 [00:21<00:00, 17.76it/s, loss=0.13]\n",
            "Epoch [46/80]: 100%|██████████| 390/390 [00:21<00:00, 17.78it/s, loss=0.103]\n",
            "Epoch [47/80]: 100%|██████████| 390/390 [00:22<00:00, 17.69it/s, loss=0.113]\n",
            "Epoch [48/80]: 100%|██████████| 390/390 [00:22<00:00, 17.64it/s, loss=0.0798]\n",
            "Epoch [49/80]: 100%|██████████| 390/390 [00:22<00:00, 17.62it/s, loss=0.0663]\n",
            "Epoch [50/80]: 100%|██████████| 390/390 [00:21<00:00, 18.01it/s, loss=0.0561]\n",
            "Epoch [51/80]: 100%|██████████| 390/390 [00:21<00:00, 17.99it/s, loss=0.0967]\n",
            "Epoch [52/80]: 100%|██████████| 390/390 [00:21<00:00, 17.95it/s, loss=0.0888]\n",
            "Epoch [53/80]: 100%|██████████| 390/390 [00:21<00:00, 18.11it/s, loss=0.0406]\n",
            "Epoch [54/80]: 100%|██████████| 390/390 [00:21<00:00, 18.21it/s, loss=0.0909]\n",
            "Epoch [55/80]: 100%|██████████| 390/390 [00:21<00:00, 18.16it/s, loss=0.0883]\n",
            "Epoch [56/80]: 100%|██████████| 390/390 [00:21<00:00, 17.97it/s, loss=0.0966]\n",
            "Epoch [57/80]: 100%|██████████| 390/390 [00:21<00:00, 18.37it/s, loss=0.0472]\n",
            "Epoch [58/80]: 100%|██████████| 390/390 [00:21<00:00, 18.51it/s, loss=0.0804]\n",
            "Epoch [59/80]: 100%|██████████| 390/390 [00:21<00:00, 18.39it/s, loss=0.0492]\n",
            "Epoch [60/80]: 100%|██████████| 390/390 [00:21<00:00, 18.01it/s, loss=0.097]\n",
            "Epoch [61/80]: 100%|██████████| 390/390 [00:21<00:00, 18.01it/s, loss=0.0467]\n",
            "Epoch [62/80]: 100%|██████████| 390/390 [00:21<00:00, 18.06it/s, loss=0.0802]\n",
            "Epoch [63/80]: 100%|██████████| 390/390 [00:21<00:00, 18.13it/s, loss=0.0675]\n",
            "Epoch [64/80]: 100%|██████████| 390/390 [00:21<00:00, 18.09it/s, loss=0.0659]\n",
            "Epoch [65/80]: 100%|██████████| 390/390 [00:21<00:00, 18.08it/s, loss=0.0625]\n",
            "Epoch [66/80]: 100%|██████████| 390/390 [00:21<00:00, 17.91it/s, loss=0.0341]\n",
            "Epoch [67/80]: 100%|██████████| 390/390 [00:21<00:00, 18.14it/s, loss=0.0303]\n",
            "Epoch [68/80]: 100%|██████████| 390/390 [00:21<00:00, 18.05it/s, loss=0.0624]\n",
            "Epoch [69/80]: 100%|██████████| 390/390 [00:21<00:00, 18.13it/s, loss=0.0347]\n",
            "Epoch [70/80]: 100%|██████████| 390/390 [00:21<00:00, 18.22it/s, loss=0.0484]\n",
            "Epoch [71/80]: 100%|██████████| 390/390 [00:21<00:00, 18.08it/s, loss=0.0408]\n",
            "Epoch [72/80]: 100%|██████████| 390/390 [00:21<00:00, 18.19it/s, loss=0.0833]\n",
            "Epoch [73/80]: 100%|██████████| 390/390 [00:21<00:00, 18.28it/s, loss=0.0417]\n",
            "Epoch [74/80]: 100%|██████████| 390/390 [00:21<00:00, 17.97it/s, loss=0.0696]\n",
            "Epoch [75/80]: 100%|██████████| 390/390 [00:21<00:00, 18.05it/s, loss=0.0614]\n",
            "Epoch [76/80]: 100%|██████████| 390/390 [00:21<00:00, 17.91it/s, loss=0.0504]\n",
            "Epoch [77/80]: 100%|██████████| 390/390 [00:21<00:00, 18.11it/s, loss=0.0558]\n",
            "Epoch [78/80]: 100%|██████████| 390/390 [00:21<00:00, 18.17it/s, loss=0.0808]\n",
            "Epoch [79/80]: 100%|██████████| 390/390 [00:21<00:00, 18.07it/s, loss=0.0611]\n",
            "Epoch [80/80]: 100%|██████████| 390/390 [00:21<00:00, 18.12it/s, loss=0.0222]\n",
            "Accuracy of the model on the test images: 84.75 %\n",
            "\n",
            "====== Training on All Nodes =====\n",
            "127.0.0.1: success\n",
            "\n",
            "====== Stopping All Nodes =====\n",
            "127.0.0.1: finish\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/pipeline/schedule/_utils.py:19: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _register_pytree_node(OrderedDict, _odict_flatten, _odict_unflatten)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/_pytree.py:254: UserWarning: <class 'collections.OrderedDict'> is already registered as pytree node. Overwriting the previous registration.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/shardformer/layer/normalization.py:45: UserWarning: Please install apex from source (https://github.com/NVIDIA/apex) to use the fused layernorm kernel\n",
            "  warnings.warn(\"Please install apex from source (https://github.com/NVIDIA/apex) to use the fused layernorm kernel\")\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/initialize.py:48: UserWarning: `config` is deprecated and will be removed soon.\n",
            "  warnings.warn(\"`config` is deprecated and will be removed soon.\")\n",
            "[04/10/24 21:56:08] INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /usr/local/lib/python3.10/dist-packages/colossalai/initialize.py:67    \n",
            "                             launch                                                                 \n",
            "                    INFO     colossalai - colossalai - INFO: Distributed environment is initialized,\n",
            "                             world size: 1                                                          \n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/kernel/extensions/utils.py:96: UserWarning: [extension] The CUDA version on the system (12.2) does not match with the version (12.1) torch was compiled with. The mismatch is found in the minor version. As the APIs are compatible, we will allow compilation to proceed. If you encounter any issue when using the built kernel, please try to build it again with fully matched CUDA versions\n",
            "  warnings.warn(\n",
            "[extension] Compiling the JIT cpu_adam_x86 kernel during runtime now\n",
            "[extension] Time taken to compile cpu_adam_x86 op: 0.10606265068054199 seconds\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/kernel/extensions/utils.py:96: UserWarning: [extension] The CUDA version on the system (12.2) does not match with the version (12.1) torch was compiled with. The mismatch is found in the minor version. As the APIs are compatible, we will allow compilation to proceed. If you encounter any issue when using the built kernel, please try to build it again with fully matched CUDA versions\n",
            "  warnings.warn(\n",
            "[extension] Compiling the JIT fused_optim_cuda kernel during runtime now\n",
            "[extension] Time taken to compile fused_optim_cuda op: 0.12424778938293457 seconds\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/nn/optimizer/hybrid_adam.py:90: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)\n",
            "  self._dummy_overflow_buf = torch.cuda.IntTensor([0])\n",
            "Epoch [1/80]:   0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/colossalai/nn/optimizer/nvme_optimizer.py:55: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  numel += p.storage().size()\n",
            "Epoch [1/80]: 100%|██████████| 390/390 [00:30<00:00, 12.94it/s, loss=1.32]\n",
            "Epoch [2/80]: 100%|██████████| 390/390 [00:29<00:00, 13.26it/s, loss=1.01]\n",
            "Epoch [3/80]: 100%|██████████| 390/390 [00:29<00:00, 13.25it/s, loss=0.966]\n",
            "Epoch [4/80]: 100%|██████████| 390/390 [00:29<00:00, 13.31it/s, loss=0.809]\n",
            "Epoch [5/80]: 100%|██████████| 390/390 [00:29<00:00, 13.33it/s, loss=0.667]\n",
            "Epoch [6/80]: 100%|██████████| 390/390 [00:29<00:00, 13.34it/s, loss=0.695]\n",
            "Epoch [7/80]: 100%|██████████| 390/390 [00:28<00:00, 13.66it/s, loss=0.527]\n",
            "Epoch [8/80]: 100%|██████████| 390/390 [00:28<00:00, 13.57it/s, loss=0.58]\n",
            "Epoch [9/80]: 100%|██████████| 390/390 [00:29<00:00, 13.24it/s, loss=0.424]\n",
            "Epoch [10/80]: 100%|██████████| 390/390 [00:29<00:00, 13.33it/s, loss=0.443]\n",
            "Epoch [11/80]: 100%|██████████| 390/390 [00:29<00:00, 13.17it/s, loss=0.474]\n",
            "Epoch [12/80]: 100%|██████████| 390/390 [00:29<00:00, 13.26it/s, loss=0.53]\n",
            "Epoch [13/80]: 100%|██████████| 390/390 [00:29<00:00, 13.26it/s, loss=0.497]\n",
            "Epoch [14/80]: 100%|██████████| 390/390 [00:29<00:00, 13.19it/s, loss=0.374]\n",
            "Epoch [15/80]: 100%|██████████| 390/390 [00:29<00:00, 13.22it/s, loss=0.418]\n",
            "Epoch [16/80]: 100%|██████████| 390/390 [00:29<00:00, 13.12it/s, loss=0.301]\n",
            "Epoch [17/80]: 100%|██████████| 390/390 [00:29<00:00, 13.28it/s, loss=0.383]\n",
            "Epoch [18/80]: 100%|██████████| 390/390 [00:29<00:00, 13.32it/s, loss=0.344]\n",
            "Epoch [19/80]: 100%|██████████| 390/390 [00:29<00:00, 13.27it/s, loss=0.347]\n",
            "Epoch [20/80]: 100%|██████████| 390/390 [00:29<00:00, 13.28it/s, loss=0.401]\n",
            "Epoch [21/80]: 100%|██████████| 390/390 [00:29<00:00, 13.17it/s, loss=0.252]\n",
            "Epoch [22/80]: 100%|██████████| 390/390 [00:29<00:00, 13.25it/s, loss=0.281]\n",
            "Epoch [23/80]: 100%|██████████| 390/390 [00:29<00:00, 13.28it/s, loss=0.228]\n",
            "Epoch [24/80]: 100%|██████████| 390/390 [00:29<00:00, 13.23it/s, loss=0.179]\n",
            "Epoch [25/80]: 100%|██████████| 390/390 [00:29<00:00, 13.26it/s, loss=0.275]\n",
            "Epoch [26/80]: 100%|██████████| 390/390 [00:29<00:00, 13.22it/s, loss=0.186]\n",
            "Epoch [27/80]: 100%|██████████| 390/390 [00:29<00:00, 13.24it/s, loss=0.251]\n",
            "Epoch [28/80]: 100%|██████████| 390/390 [00:29<00:00, 13.21it/s, loss=0.258]\n",
            "Epoch [29/80]: 100%|██████████| 390/390 [00:29<00:00, 13.18it/s, loss=0.208]\n",
            "Epoch [30/80]: 100%|██████████| 390/390 [00:29<00:00, 13.27it/s, loss=0.185]\n",
            "Epoch [31/80]: 100%|██████████| 390/390 [00:29<00:00, 13.19it/s, loss=0.224]\n",
            "Epoch [32/80]: 100%|██████████| 390/390 [00:29<00:00, 13.27it/s, loss=0.236]\n",
            "Epoch [33/80]: 100%|██████████| 390/390 [00:29<00:00, 13.36it/s, loss=0.225]\n",
            "Epoch [34/80]: 100%|██████████| 390/390 [00:29<00:00, 13.29it/s, loss=0.242]\n",
            "Epoch [35/80]: 100%|██████████| 390/390 [00:29<00:00, 13.32it/s, loss=0.127]\n",
            "Epoch [36/80]: 100%|██████████| 390/390 [00:29<00:00, 13.25it/s, loss=0.233]\n",
            "Epoch [37/80]: 100%|██████████| 390/390 [00:29<00:00, 13.22it/s, loss=0.186]\n",
            "Epoch [38/80]: 100%|██████████| 390/390 [00:29<00:00, 13.24it/s, loss=0.244]\n",
            "Epoch [39/80]: 100%|██████████| 390/390 [00:29<00:00, 13.29it/s, loss=0.132]\n",
            "Epoch [40/80]: 100%|██████████| 390/390 [00:29<00:00, 13.27it/s, loss=0.144]\n",
            "Epoch [41/80]: 100%|██████████| 390/390 [00:29<00:00, 13.02it/s, loss=0.112]\n",
            "Epoch [42/80]: 100%|██████████| 390/390 [00:28<00:00, 13.56it/s, loss=0.13]\n",
            "Epoch [43/80]: 100%|██████████| 390/390 [00:29<00:00, 13.30it/s, loss=0.163]\n",
            "Epoch [44/80]: 100%|██████████| 390/390 [00:29<00:00, 13.11it/s, loss=0.0756]\n",
            "Epoch [45/80]: 100%|██████████| 390/390 [00:29<00:00, 13.03it/s, loss=0.14]\n",
            "Epoch [46/80]: 100%|██████████| 390/390 [00:29<00:00, 13.04it/s, loss=0.09]\n",
            "Epoch [47/80]: 100%|██████████| 390/390 [00:30<00:00, 12.96it/s, loss=0.158]\n",
            "Epoch [48/80]: 100%|██████████| 390/390 [00:29<00:00, 13.07it/s, loss=0.0641]\n",
            "Epoch [49/80]: 100%|██████████| 390/390 [00:29<00:00, 13.05it/s, loss=0.0504]\n",
            "Epoch [50/80]: 100%|██████████| 390/390 [00:29<00:00, 13.09it/s, loss=0.109]\n",
            "Epoch [51/80]: 100%|██████████| 390/390 [00:30<00:00, 12.91it/s, loss=0.11]\n",
            "Epoch [52/80]: 100%|██████████| 390/390 [00:29<00:00, 13.09it/s, loss=0.106]\n",
            "Epoch [53/80]: 100%|██████████| 390/390 [00:29<00:00, 13.03it/s, loss=0.124]\n",
            "Epoch [54/80]: 100%|██████████| 390/390 [00:29<00:00, 13.03it/s, loss=0.108]\n",
            "Epoch [55/80]: 100%|██████████| 390/390 [00:29<00:00, 13.02it/s, loss=0.0948]\n",
            "Epoch [56/80]: 100%|██████████| 390/390 [00:30<00:00, 12.95it/s, loss=0.129]\n",
            "Epoch [57/80]: 100%|██████████| 390/390 [00:29<00:00, 13.11it/s, loss=0.0858]\n",
            "Epoch [58/80]: 100%|██████████| 390/390 [00:29<00:00, 13.12it/s, loss=0.056]\n",
            "Epoch [59/80]: 100%|██████████| 390/390 [00:29<00:00, 13.09it/s, loss=0.0934]\n",
            "Epoch [60/80]: 100%|██████████| 390/390 [00:29<00:00, 13.10it/s, loss=0.0714]\n",
            "Epoch [61/80]: 100%|██████████| 390/390 [00:30<00:00, 12.93it/s, loss=0.0748]\n",
            "Epoch [62/80]: 100%|██████████| 390/390 [00:29<00:00, 13.04it/s, loss=0.0553]\n",
            "Epoch [63/80]: 100%|██████████| 390/390 [00:29<00:00, 13.07it/s, loss=0.0679]\n",
            "Epoch [64/80]: 100%|██████████| 390/390 [00:30<00:00, 12.99it/s, loss=0.0777]\n",
            "Epoch [65/80]: 100%|██████████| 390/390 [00:29<00:00, 13.04it/s, loss=0.0432]\n",
            "Epoch [66/80]: 100%|██████████| 390/390 [00:30<00:00, 12.98it/s, loss=0.0446]\n",
            "Epoch [67/80]: 100%|██████████| 390/390 [00:29<00:00, 13.07it/s, loss=0.0308]\n",
            "Epoch [68/80]: 100%|██████████| 390/390 [00:30<00:00, 12.93it/s, loss=0.0314]\n",
            "Epoch [69/80]: 100%|██████████| 390/390 [00:30<00:00, 12.94it/s, loss=0.0597]\n",
            "Epoch [70/80]: 100%|██████████| 390/390 [00:30<00:00, 12.91it/s, loss=0.0329]\n",
            "Epoch [71/80]: 100%|██████████| 390/390 [00:30<00:00, 12.98it/s, loss=0.0252]\n",
            "Epoch [72/80]: 100%|██████████| 390/390 [00:29<00:00, 13.01it/s, loss=0.0764]\n",
            "Epoch [73/80]: 100%|██████████| 390/390 [00:30<00:00, 12.94it/s, loss=0.0595]\n",
            "Epoch [74/80]: 100%|██████████| 390/390 [00:30<00:00, 12.92it/s, loss=0.0325]\n",
            "Epoch [75/80]: 100%|██████████| 390/390 [00:29<00:00, 13.17it/s, loss=0.0546]\n",
            "Epoch [76/80]: 100%|██████████| 390/390 [00:28<00:00, 13.45it/s, loss=0.0846]\n",
            "Epoch [77/80]: 100%|██████████| 390/390 [00:28<00:00, 13.64it/s, loss=0.0717]\n",
            "Epoch [78/80]: 100%|██████████| 390/390 [00:29<00:00, 13.30it/s, loss=0.0908]\n",
            "Epoch [79/80]: 100%|██████████| 390/390 [00:29<00:00, 13.41it/s, loss=0.0345]\n",
            "Epoch [80/80]: 100%|██████████| 390/390 [00:29<00:00, 13.42it/s, loss=0.124]\n",
            "Accuracy of the model on the test images: 84.78 %\n",
            "\n",
            "====== Training on All Nodes =====\n",
            "127.0.0.1: success\n",
            "\n",
            "====== Stopping All Nodes =====\n",
            "127.0.0.1: finish\n"
          ]
        }
      ],
      "source": [
        "# Number of GPUs available. Since we are in Google Colab which has only 1 GPU, set it to 1.\n",
        "# Change this accordingly if running in other environment.\n",
        "num_gpu = 1\n",
        "\n",
        "# train with torch DDP with fp32\n",
        "train_with_DDP_fp32_command = f\"{colossal_ai_run} --nproc_per_node {num_gpu} {resnet_experiment_train_script_path} -c {resnet_experiment_model_path}/ckpt-fp32\"\n",
        "!{train_with_DDP_fp32_command}\n",
        "\n",
        "# train with torch DDP with mixed precision training\n",
        "train_with_DDP_fp16_command = f\"{colossal_ai_run} --nproc_per_node {num_gpu} {resnet_experiment_train_script_path} -c {resnet_experiment_model_path}/ckpt-fp16 -p torch_ddp_fp16\"\n",
        "!{train_with_DDP_fp16_command}\n",
        "\n",
        "# train with low level zero\n",
        "train_with_low_level_zero_command = f\"{colossal_ai_run} --nproc_per_node {num_gpu} {resnet_experiment_train_script_path} -c {resnet_experiment_model_path}/ckpt-low_level_zero -p low_level_zero\"\n",
        "!{train_with_low_level_zero_command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKBi3-9y-XCf"
      },
      "source": [
        "# Evaluation and reproduce performance table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pcdnlpKUQQ2r",
        "outputId": "2ac72506-11f1-4562-f333-5b79b5d27208"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"reproduced_result\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"ResNet-18\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Booster DDP with FP32\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"84.54%\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Booster DDP with FP16\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"84.77%\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Booster Low Level Zero\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"84.78%\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "reproduced_result"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-7838e615-649f-429e-8171-a74da7dd3e6a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Booster DDP with FP32</th>\n",
              "      <th>Booster DDP with FP16</th>\n",
              "      <th>Booster Low Level Zero</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ResNet-18</td>\n",
              "      <td>84.54%</td>\n",
              "      <td>84.77%</td>\n",
              "      <td>84.78%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7838e615-649f-429e-8171-a74da7dd3e6a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7838e615-649f-429e-8171-a74da7dd3e6a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7838e615-649f-429e-8171-a74da7dd3e6a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       Model Booster DDP with FP32 Booster DDP with FP16  \\\n",
              "0  ResNet-18                84.54%                84.77%   \n",
              "\n",
              "  Booster Low Level Zero  \n",
              "0                 84.78%  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "ddp_fp32_result_path = './ddp_fp32.txt'\n",
        "ddp_fp16_result_path = './ddp_fp16.txt'\n",
        "low_level_zero_result_path = './low_level_zero.txt'\n",
        "\n",
        "eval_with_DDP_fp32_command = f\"python {resnet_experiment_eval_script_path} -c {resnet_experiment_model_path}/ckpt-fp32 -e 80 > {ddp_fp32_result_path}\"\n",
        "!{eval_with_DDP_fp32_command}\n",
        "eval_with_DDP_fp16_command = f\"python {resnet_experiment_eval_script_path} -c {resnet_experiment_model_path}/ckpt-fp16 -e 80 > {ddp_fp16_result_path}\"\n",
        "!{eval_with_DDP_fp16_command}\n",
        "eval_with_low_level_zero_command = f\"python {resnet_experiment_eval_script_path} -c {resnet_experiment_model_path}/ckpt-low_level_zero -e 80 > {low_level_zero_result_path}\"\n",
        "!{eval_with_low_level_zero_command}\n",
        "\n",
        "with open(ddp_fp32_result_path, 'r') as file:\n",
        "    ddp_fp32_result_txt = file.read()\n",
        "\n",
        "with open(ddp_fp16_result_path, 'r') as file:\n",
        "    ddp_fp16_result_txt = file.read()\n",
        "\n",
        "with open(low_level_zero_result_path, 'r') as file:\n",
        "    low_level_zero_result_txt = file.read()\n",
        "\n",
        "accuracy_pattern = r'[0-9]+\\.[0-9]+'\n",
        "match_ddp_fp32 = re.search(accuracy_pattern, ddp_fp32_result_txt).group()\n",
        "match_ddp_fp16 = re.search(accuracy_pattern, ddp_fp16_result_txt).group()\n",
        "match_low_level_zero = re.search(accuracy_pattern, low_level_zero_result_txt).group()\n",
        "\n",
        "headers = ['Model', 'Booster DDP with FP32', 'Booster DDP with FP16', 'Booster Low Level Zero']\n",
        "performances = ['ResNet-18', f'{match_ddp_fp32}%', f'{match_ddp_fp16}%', f'{match_low_level_zero}%']\n",
        "reproduced_result = pd.DataFrame([performances], columns=headers).reset_index(drop=True)\n",
        "reproduced_result.head()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}